# DUCI: Dataset Usage Cardinality Inference
This repository contains the implementation of the paper: 

***How Much of My Dataset Did You Use? Quantitative Data Usage Inference in Machine Learning***

## üîç Overview

DUCI (Dataset Usage Cardinality Inference) introduces a novel method to quantitatively assess the extent to which a dataset has been utilized in training a machine learning model. Unlike traditional binary membership inference attacks, DUCI provides a fine-grained analysis, estimating the exact proportion of data used. The proposed algorithm leverages debiased membership guesses and achieves performance comparable to the optimal Maximum Likelihood Estimation approach, with significantly reduced computational cost.

---

## üìÅ Repository Updates

Thank you for your interest in this project!

- The code for the book copyright infringement case study has been added. 
- The complete version of the project will be released soon as well.
- We are glad to share that DUCI is integrated into the PrivacyMeter toolkit, which provides tools for auditing privacy risks in machine learning models. You can explore PrivacyMeter here: [PrivacyMeter](https://github.com/privacytrustlab/ml_privacy_meter).

## üöÄ Getting Started

To execute our code, please refer to the `README.md` file in each folder. These files contain detailed instructions on running experiments, and reproducing results.

## üìö Citation

If you find this work useful in your research, please cite our paper:

```bibtex
@inproceedings{tongmuch,
  title={How Much of My Dataset Did You Use? Quantitative Data Usage Inference in Machine Learning},
  author={Tong, Yao and Ye, Jiayuan and Zarifzadeh, Sajjad and Shokri, Reza},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025},
  url={https://openreview.net/forum?id=EUSkm2sVJ6}
}
```
